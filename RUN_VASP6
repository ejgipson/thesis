#!/bin/bash
#SBATCH --job-name=XXXXX
#SBATCH --account=designlab
#SBATCH --time=60:00:00
#SBATCH --mail-type=END
#SBATCH --mail-user=egipson@uwyo.edu
#
##Resource Request (2servers, 32 mpi-tasks/server.4GB menory/cpu_core)
##In this case an mpi-task is equivalent to a cpu core
#
#SBATCH --nodes=2
#SBATCH --ntasks-per-node=8
#SBATCH --mem=16GB
#SBATCH --cpus-per-task=1
#
export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK
#export OMP_NUM_THREADS=1
echo "SLURM_JOB_ID:" $SLURM_JOB_ID
echo "SLURM_JOB_NAME:" $SLURM_JOB_NAME
echo "SLURM_JOB_PARTITION" $SLURM_JOB_PARTITION
echo "SLURM_JOB_NUM_NODES:" $SLURM_JOB_NUM_NODES
echo "SLURM_JOB_NODELIST:" $SLURM_JOB_NODELIST
echo "SLURM_JOB_CPUS_PER_NODE:" $SLURM_JOB_CPUS_PER_NODE
echo "SLURM_TASKS_PER_NODE:" $SLURM_TASKS_PER_NODE
echo "SLURM_CPUS_PER_TASK:" $SLURM_CPUS_PER_TASK
echo "SLURM_CPUS_ON_NODE:" $SLURM_CPUS_ON_NODE
echo "OMP_NUM_THREADS:" $OMP_NUM_THREADS

#module load  gcc/12.2.0 openmpi/4.1.4 fftw/3.3.10 netlib-scalapack/2.2.0-ompi netlib-lapack/3.10.1 openblas/0.3.21
module load gcc/12.2.0 openmpi/4.1.4 fftw/3.3.10-ompi openblas/0.3.21 netlib-scalapack/2.2.0-ompi wannier90/3.1.0 hdf5/1.12.2-ompi



TOTAL_NP=$(($SLURM_JOB_NUM_NODES*$SLURM_CPUS_ON_NODE/$SLURM_CPUS_PER_TASK))
echo "Total NPs: " $TOTAL_NP

start=$(date +'%D %T')
echo "Start:" $start

#/usr/bin/time -o job_log.out --verbose srun /project/designlab/vasp/beartooth/vasp.6.3.2/bin/vasp_std
/usr/bin/time -o job_log.out --verbose srun /project/designlab/vasp/beartooth/vasp.6.3.2/bin/vasp_std


end=$(date +'%D %T')
echo "End:" $end

start_secs=$(date --date="$start" '+%s')
end_secs=$(date --date="$end"   '+%s')
duration=$((end_secs - start_secs))
echo "Duration:" $duration"sec"
echo "Done."

